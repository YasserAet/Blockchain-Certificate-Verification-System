{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e25c97",
   "metadata": {},
   "source": [
    "# ü§ñ ML Training Pipeline - Random Forest Models\n",
    "\n",
    "This notebook demonstrates the complete machine learning training pipeline for the Blockchain Certificate Verification System.\n",
    "\n",
    "## üìä Datasets Covered:\n",
    "1. **Coursera Course Dataset** - Regression on course ratings\n",
    "2. **Text Document Classification** - Document type classification  \n",
    "3. **OCR Character Recognition** - Image-based character classification\n",
    "4. **Synthetic Fraud Detection** - Binary classification for fraud detection\n",
    "\n",
    "## üéØ Models Used:\n",
    "- **Random Forest Classifier** - For classification tasks\n",
    "- **Random Forest Regressor** - For rating prediction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19527658",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d839d98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "NumPy version: 2.3.5\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea0648",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Dataset 1 - Coursera Course Ratings\n",
    "\n",
    "Load and explore the Coursera course dataset for regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da91dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Coursera dataset\n",
    "coursera_path = \"../Datasets/Coursera Course Dataset/coursea_data.csv\"\n",
    "\n",
    "if os.path.exists(coursera_path):\n",
    "    df_coursera = pd.read_csv(coursera_path)\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df_coursera.shape}\")\n",
    "    print(f\"\\nColumns: {df_coursera.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(df_coursera.head())\n",
    "    \n",
    "    print(\"\\nüìä Dataset Info:\")\n",
    "    print(df_coursera.info())\n",
    "    \n",
    "    print(\"\\nüìà Statistical Summary:\")\n",
    "    display(df_coursera.describe())\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {coursera_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb08bfa",
   "metadata": {},
   "source": [
    "### üìä Visualize Course Ratings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_coursera' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Rating distribution\n",
    "    axes[0, 0].hist(df_coursera['course_rating'], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Course Rating Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Rating')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Students enrolled distribution\n",
    "    axes[0, 1].hist(df_coursera['course_students_enrolled'], bins=30, color='lightgreen', edgecolor='black')\n",
    "    axes[0, 1].set_title('Students Enrolled Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Number of Students')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # Difficulty distribution\n",
    "    difficulty_counts = df_coursera['course_difficulty'].value_counts()\n",
    "    axes[1, 0].bar(difficulty_counts.index, difficulty_counts.values, color='coral', edgecolor='black')\n",
    "    axes[1, 0].set_title('Course Difficulty Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Difficulty Level')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Rating vs Students (scatter)\n",
    "    axes[1, 1].scatter(df_coursera['course_students_enrolled'], \n",
    "                       df_coursera['course_rating'], \n",
    "                       alpha=0.5, color='purple')\n",
    "    axes[1, 1].set_title('Rating vs Students Enrolled', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Students Enrolled')\n",
    "    axes[1, 1].set_ylabel('Course Rating')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Rating Statistics:\")\n",
    "    print(f\"  Mean Rating: {df_coursera['course_rating'].mean():.2f}\")\n",
    "    print(f\"  Median Rating: {df_coursera['course_rating'].median():.2f}\")\n",
    "    print(f\"  Std Dev: {df_coursera['course_rating'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018038d6",
   "metadata": {},
   "source": [
    "### ü§ñ Train Random Forest Regressor on Coursera Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2278f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_coursera' in locals():\n",
    "    # Prepare features and target\n",
    "    X = df_coursera.drop('course_rating', axis=1).select_dtypes(include=[np.number])\n",
    "    y = df_coursera['course_rating']\n",
    "    \n",
    "    print(f\"Features: {X.columns.tolist()}\")\n",
    "    print(f\"Target: course_rating\")\n",
    "    print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nüîÑ Training Random Forest Regressor...\")\n",
    "    rf_regressor = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_regressor.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model Training Complete!\")\n",
    "    print(f\"\\nüìä Performance Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_regressor.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüéØ Feature Importance:\")\n",
    "    display(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f92aa",
   "metadata": {},
   "source": [
    "### üìà Visualize Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c79aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_pred' in locals():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    axes[0].scatter(y_test, y_pred, alpha=0.6, color='blue')\n",
    "    axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0].set_xlabel('Actual Rating', fontsize=12)\n",
    "    axes[0].set_ylabel('Predicted Rating', fontsize=12)\n",
    "    axes[0].set_title('Actual vs Predicted Ratings', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Residuals\n",
    "    residuals = y_test - y_pred\n",
    "    axes[1].scatter(y_pred, residuals, alpha=0.6, color='green')\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[1].set_xlabel('Predicted Rating', fontsize=12)\n",
    "    axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "    axes[1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # Feature Importance\n",
    "    axes[2].barh(feature_importance['feature'], feature_importance['importance'], color='purple')\n",
    "    axes[2].set_xlabel('Importance', fontsize=12)\n",
    "    axes[2].set_title('Feature Importance', fontsize=14, fontweight='bold')\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be5e3a",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÑ Step 3: Dataset 2 - Text Document Classification\n",
    "\n",
    "Load and classify text documents based on their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c492054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Text Classification dataset\n",
    "text_path = \"../Datasets/Text Document Classification Dataset/df_file.csv\"\n",
    "\n",
    "if os.path.exists(text_path):\n",
    "    df_text = pd.read_csv(text_path)\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df_text.shape}\")\n",
    "    print(f\"\\nColumns: {df_text.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    display(df_text.head(10))\n",
    "    \n",
    "    print(\"\\nüìä Dataset Info:\")\n",
    "    print(df_text.info())\n",
    "    \n",
    "    # Check class distribution\n",
    "    if len(df_text.columns) > 1:\n",
    "        print(f\"\\nüìà Class Distribution:\")\n",
    "        display(df_text.iloc[:, -1].value_counts())\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00f1a7",
   "metadata": {},
   "source": [
    "---\n",
    "## üñºÔ∏è Step 4: Dataset 3 - OCR Character Recognition\n",
    "\n",
    "Process OCR images and train a classifier for character recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb52f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OCR images\n",
    "ocr_dir = \"../Datasets/standard OCR dataset\"\n",
    "ocr_features = []\n",
    "ocr_labels = []\n",
    "sample_images = []\n",
    "\n",
    "print(\"üîÑ Loading OCR images...\")\n",
    "\n",
    "if os.path.exists(ocr_dir):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(ocr_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    img_array = np.array(img).flatten()[:100]\n",
    "                    if len(img_array) == 100:\n",
    "                        ocr_features.append(img_array)\n",
    "                        label = os.path.basename(root)\n",
    "                        ocr_labels.append(label)\n",
    "                        \n",
    "                        # Save first 12 images for visualization\n",
    "                        if len(sample_images) < 12:\n",
    "                            sample_images.append((img, label))\n",
    "                        count += 1\n",
    "                except:\n",
    "                    pass\n",
    "            if count >= 500:  # Limit to 500 images for notebook\n",
    "                break\n",
    "        if count >= 500:\n",
    "            break\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(ocr_features)} images\")\n",
    "    print(f\"üìä Unique labels: {len(set(ocr_labels))}\")\n",
    "    print(f\"üî§ Labels: {sorted(set(ocr_labels))[:20]}...\")  # Show first 20 labels\n",
    "else:\n",
    "    print(f\"‚ùå Directory not found: {ocr_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccae4e",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Visualize Sample OCR Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sample_images) > 0:\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (img, label) in enumerate(sample_images[:12]):\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f'Label: {label}', fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample OCR Images', fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b6cf3",
   "metadata": {},
   "source": [
    "### ü§ñ Train Random Forest Classifier on OCR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28717fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ocr_features) > 10:\n",
    "    # Prepare data\n",
    "    X_ocr = pd.DataFrame(ocr_features)\n",
    "    y_ocr = pd.Series(ocr_labels)\n",
    "    \n",
    "    print(f\"Dataset shape: X={X_ocr.shape}, y={y_ocr.shape}\")\n",
    "    print(f\"Number of classes: {y_ocr.nunique()}\")\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_ocr_encoded = le.fit_transform(y_ocr)\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique_classes = np.unique(y_ocr_encoded)\n",
    "    min_class_size = min(np.bincount(y_ocr_encoded))\n",
    "    stratify = y_ocr_encoded if min_class_size >= 2 else None\n",
    "    \n",
    "    # Split data\n",
    "    X_train_ocr, X_test_ocr, y_train_ocr, y_test_ocr = train_test_split(\n",
    "        X_ocr, y_ocr_encoded, test_size=0.2, random_state=42, stratify=stratify\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_ocr = StandardScaler()\n",
    "    X_train_ocr_scaled = scaler_ocr.fit_transform(X_train_ocr)\n",
    "    X_test_ocr_scaled = scaler_ocr.transform(X_test_ocr)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nüîÑ Training Random Forest Classifier...\")\n",
    "    rf_ocr = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_ocr.fit(X_train_ocr_scaled, y_train_ocr)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_ocr = rf_ocr.predict(X_test_ocr_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy_ocr = accuracy_score(y_test_ocr, y_pred_ocr)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model Training Complete!\")\n",
    "    print(f\"\\nüìä Performance Metrics:\")\n",
    "    print(f\"  Accuracy: {accuracy_ocr:.4f}\")\n",
    "    print(f\"  Number of samples: {len(X_ocr)}\")\n",
    "    print(f\"  Training samples: {len(X_train_ocr)}\")\n",
    "    print(f\"  Test samples: {len(X_test_ocr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfa5d0",
   "metadata": {},
   "source": [
    "### üìä Visualize OCR Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_pred_ocr' in locals():\n",
    "    # Confusion Matrix\n",
    "    cm_ocr = confusion_matrix(y_test_ocr, y_pred_ocr)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Confusion Matrix (show subset for readability)\n",
    "    if cm_ocr.shape[0] <= 10:\n",
    "        sns.heatmap(cm_ocr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "        axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Predicted Label')\n",
    "        axes[0].set_ylabel('True Label')\n",
    "    else:\n",
    "        # Show subset of confusion matrix for many classes\n",
    "        subset_size = min(10, cm_ocr.shape[0])\n",
    "        cm_subset = cm_ocr[:subset_size, :subset_size]\n",
    "        sns.heatmap(cm_subset, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "        axes[0].set_title(f'Confusion Matrix (First {subset_size} classes)', fontsize=14, fontweight='bold')\n",
    "        axes[0].set_xlabel('Predicted Label')\n",
    "        axes[0].set_ylabel('True Label')\n",
    "    \n",
    "    # Class distribution\n",
    "    class_counts = pd.Series(y_ocr_encoded).value_counts().head(15)\n",
    "    axes[1].barh(range(len(class_counts)), class_counts.values, color='teal')\n",
    "    axes[1].set_yticks(range(len(class_counts)))\n",
    "    axes[1].set_yticklabels([le.inverse_transform([i])[0] for i in class_counts.index])\n",
    "    axes[1].set_xlabel('Count')\n",
    "    axes[1].set_title('Top 15 Character Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927135f7",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Step 5: Dataset 4 - Synthetic Fraud Detection\n",
    "\n",
    "Generate synthetic fraud data and train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bcaf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic fraud detection data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Create features\n",
    "X_fraud = np.random.randn(n_samples, 10)\n",
    "\n",
    "# Create target with patterns\n",
    "y_fraud = ((X_fraud[:, 0] > 0.5) & (X_fraud[:, 1] < -0.5) | (np.abs(X_fraud[:, 2]) > 2)).astype(int)\n",
    "\n",
    "X_fraud_df = pd.DataFrame(X_fraud, columns=[f'feature_{i}' for i in range(10)])\n",
    "\n",
    "print(f\"‚úÖ Generated synthetic fraud dataset\")\n",
    "print(f\"Shape: {X_fraud_df.shape}\")\n",
    "print(f\"Fraud cases: {y_fraud.sum()} ({y_fraud.sum()/len(y_fraud)*100:.1f}%)\")\n",
    "print(f\"Normal cases: {(1-y_fraud).sum()} ({(1-y_fraud).sum()/len(y_fraud)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìä First 5 rows:\")\n",
    "display(X_fraud_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccfd3a5",
   "metadata": {},
   "source": [
    "### ü§ñ Train Random Forest Classifier for Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(\n",
    "    X_fraud_df, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_fraud = StandardScaler()\n",
    "X_train_fraud_scaled = scaler_fraud.fit_transform(X_train_fraud)\n",
    "X_test_fraud_scaled = scaler_fraud.transform(X_test_fraud)\n",
    "\n",
    "# Train model\n",
    "print(\"üîÑ Training Random Forest Classifier...\")\n",
    "rf_fraud = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_fraud.fit(X_train_fraud_scaled, y_train_fraud)\n",
    "\n",
    "# Predictions\n",
    "y_pred_fraud = rf_fraud.predict(X_test_fraud_scaled)\n",
    "y_pred_fraud_proba = rf_fraud.predict_proba(X_test_fraud_scaled)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "accuracy_fraud = accuracy_score(y_test_fraud, y_pred_fraud)\n",
    "precision_fraud = precision_score(y_test_fraud, y_pred_fraud)\n",
    "recall_fraud = recall_score(y_test_fraud, y_pred_fraud)\n",
    "f1_fraud = f1_score(y_test_fraud, y_pred_fraud)\n",
    "\n",
    "print(f\"\\n‚úÖ Model Training Complete!\")\n",
    "print(f\"\\nüìä Performance Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy_fraud:.4f}\")\n",
    "print(f\"  Precision: {precision_fraud:.4f}\")\n",
    "print(f\"  Recall:    {recall_fraud:.4f}\")\n",
    "print(f\"  F1 Score:  {f1_fraud:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance_fraud = pd.DataFrame({\n",
    "    'feature': X_fraud_df.columns,\n",
    "    'importance': rf_fraud.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nüéØ Top 5 Features:\")\n",
    "display(feature_importance_fraud.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59eae1c",
   "metadata": {},
   "source": [
    "### üìä Visualize Fraud Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5121aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_fraud = confusion_matrix(y_test_fraud, y_pred_fraud)\n",
    "sns.heatmap(cm_fraud, annot=True, fmt='d', cmap='Reds', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Predicted Label')\n",
    "axes[0, 0].set_ylabel('True Label')\n",
    "axes[0, 0].set_xticklabels(['Normal', 'Fraud'])\n",
    "axes[0, 0].set_yticklabels(['Normal', 'Fraud'])\n",
    "\n",
    "# Feature Importance\n",
    "axes[0, 1].barh(feature_importance_fraud['feature'], feature_importance_fraud['importance'], color='orange')\n",
    "axes[0, 1].set_xlabel('Importance', fontsize=12)\n",
    "axes[0, 1].set_title('Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3, axis='x')\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test_fraud, y_pred_fraud_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "axes[1, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1, 0].set_xlim([0.0, 1.0])\n",
    "axes[1, 0].set_ylim([0.0, 1.05])\n",
    "axes[1, 0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1, 0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1, 0].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(loc=\"lower right\")\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Class Distribution\n",
    "class_dist = pd.Series(y_fraud).value_counts()\n",
    "axes[1, 1].pie(class_dist.values, labels=['Normal', 'Fraud'], autopct='%1.1f%%', \n",
    "               colors=['lightblue', 'lightcoral'], startangle=90)\n",
    "axes[1, 1].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21688ff",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Step 6: Model Comparison & Summary\n",
    "\n",
    "Compare all trained models and save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fcd3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results_summary = {\n",
    "    'Coursera Regressor': {\n",
    "        'Type': 'Regression',\n",
    "        'Metric': 'RMSE',\n",
    "        'Score': rmse if 'rmse' in locals() else 'N/A',\n",
    "        'Samples': len(df_coursera) if 'df_coursera' in locals() else 0\n",
    "    },\n",
    "    'OCR Classifier': {\n",
    "        'Type': 'Classification',\n",
    "        'Metric': 'Accuracy',\n",
    "        'Score': accuracy_ocr if 'accuracy_ocr' in locals() else 'N/A',\n",
    "        'Samples': len(ocr_features) if 'ocr_features' in locals() else 0\n",
    "    },\n",
    "    'Fraud Classifier': {\n",
    "        'Type': 'Classification',\n",
    "        'Metric': 'Accuracy',\n",
    "        'Score': accuracy_fraud if 'accuracy_fraud' in locals() else 'N/A',\n",
    "        'Samples': n_samples\n",
    "    }\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_summary).T\n",
    "print(\"=\"*60)\n",
    "print(\"üìä MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "display(results_df)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "models = list(results_summary.keys())\n",
    "scores = [results_summary[m]['Score'] for m in models if results_summary[m]['Score'] != 'N/A']\n",
    "model_names = [m for m in models if results_summary[m]['Score'] != 'N/A']\n",
    "\n",
    "bars = ax.bar(range(len(model_names)), scores, color=['skyblue', 'lightgreen', 'coral'])\n",
    "ax.set_xticks(range(len(model_names)))\n",
    "ax.set_xticklabels(model_names, rotation=0)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, score) in enumerate(zip(bars, scores)):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{score:.4f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Training Pipeline Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029e152",
   "metadata": {},
   "source": [
    "### üíæ Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b79c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "print(\"üíæ Saving models...\")\n",
    "\n",
    "if 'rf_regressor' in locals():\n",
    "    joblib.dump(rf_regressor, models_dir / 'coursera_regressor.pkl')\n",
    "    joblib.dump(scaler, models_dir / 'coursera_scaler.pkl')\n",
    "    print(\"  ‚úÖ Coursera Regressor saved\")\n",
    "\n",
    "if 'rf_ocr' in locals():\n",
    "    joblib.dump(rf_ocr, models_dir / 'ocr_classifier.pkl')\n",
    "    joblib.dump(scaler_ocr, models_dir / 'ocr_scaler.pkl')\n",
    "    joblib.dump(le, models_dir / 'ocr_label_encoder.pkl')\n",
    "    print(\"  ‚úÖ OCR Classifier saved\")\n",
    "\n",
    "if 'rf_fraud' in locals():\n",
    "    joblib.dump(rf_fraud, models_dir / 'fraud_classifier.pkl')\n",
    "    joblib.dump(scaler_fraud, models_dir / 'fraud_scaler.pkl')\n",
    "    print(\"  ‚úÖ Fraud Classifier saved\")\n",
    "\n",
    "# Save results summary\n",
    "results_summary_detailed = {\n",
    "    'coursera_regressor': {\n",
    "        'rmse': float(rmse) if 'rmse' in locals() else None,\n",
    "        'mae': float(mae) if 'mae' in locals() else None,\n",
    "        'r2': float(r2) if 'r2' in locals() else None\n",
    "    },\n",
    "    'ocr_classifier': {\n",
    "        'accuracy': float(accuracy_ocr) if 'accuracy_ocr' in locals() else None,\n",
    "        'samples': len(ocr_features) if 'ocr_features' in locals() else 0\n",
    "    },\n",
    "    'fraud_classifier': {\n",
    "        'accuracy': float(accuracy_fraud) if 'accuracy_fraud' in locals() else None,\n",
    "        'precision': float(precision_fraud) if 'precision_fraud' in locals() else None,\n",
    "        'recall': float(recall_fraud) if 'recall_fraud' in locals() else None,\n",
    "        'f1_score': float(f1_fraud) if 'f1_fraud' in locals() else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(models_dir / 'training_results.json', 'w') as f:\n",
    "    json.dump(results_summary_detailed, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ All models and results saved to 'models/' directory!\")\n",
    "print(f\"\\nSaved files:\")\n",
    "for file in sorted(models_dir.glob('*')):\n",
    "    print(f\"  - {file.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
